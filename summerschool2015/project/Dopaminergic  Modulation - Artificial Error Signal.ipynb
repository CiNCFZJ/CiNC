{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Dopaminergic Error Signal"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "In this notebook, we will introduce a more plausible way to calculate the prediction error signal for reinforcement learning."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "We start with the same implementation as before but without calculating the values (and weights from states to actions) explicitly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nest\n",
      "import nest.raster_plot as rplt\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import environment as env\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "env.set_environment(0)\n",
      "\n",
      "NUM_ITERATIONS = 2000\n",
      "LEARNING_RATE = 0.05\n",
      "NUM_STATE_NEURONS = 20\n",
      "NUM_WTA_NEURONS = 50\n",
      "WEIGHT_SCALING = 100 / NUM_STATE_NEURONS\n",
      "\n",
      "nest.ResetKernel()\n",
      "nest.set_verbosity(\"M_DEBUG\")\n",
      "\n",
      "rank = nest.Rank()\n",
      "size = nest.NumProcesses() \n",
      "seed = np.random.randint(0, 1000000)\n",
      "num_threads = 1\n",
      "nest.SetKernelStatus({\"local_num_threads\": num_threads})\n",
      "nest.SetKernelStatus({\"rng_seeds\": range(seed+num_threads * size + 1, seed + 2 * (num_threads * size) + 1),\n",
      "        \t\t      \"grng_seed\": seed+size+num_threads,\n",
      "                      \"resolution\": 0.1})\n",
      "\n",
      "# Create states\n",
      "world_dim = env.get_world_dimensions()\n",
      "states = []\n",
      "for i in range(world_dim['x']):\n",
      "    states.append([])\n",
      "    for j in range(world_dim['y']):\n",
      "        states[i].append(nest.Create('iaf_psc_alpha', NUM_STATE_NEURONS))\n",
      "all_states = np.ravel(states).tolist()\n",
      "\n",
      "# Create actions\n",
      "num_actions = env.get_num_possible_actions()\n",
      "actions = []\n",
      "for i in range(num_actions):\n",
      "    actions.append(nest.Create('iaf_psc_alpha', NUM_WTA_NEURONS))\n",
      "all_actions = np.ravel(actions).tolist()\n",
      "\n",
      "# Create WTA circuit\n",
      "wta_ex_weights = 10.5\n",
      "wta_inh_weights = -2.6\n",
      "wta_ex_inh_weights = 2.8\n",
      "wta_noise_weights = 2.1\n",
      "\n",
      "wta_inh_neurons = nest.Create('iaf_psc_alpha', NUM_WTA_NEURONS)\n",
      "\n",
      "for i in range(len(actions)):\n",
      "    nest.Connect(actions[i], actions[i], 'all_to_all', {'weight': wta_ex_weights})\n",
      "    nest.Connect(actions[i], wta_inh_neurons, 'all_to_all', {'weight': wta_ex_inh_weights}) \n",
      "\n",
      "nest.Connect(wta_inh_neurons, all_actions, 'all_to_all', {'weight': wta_inh_weights})\n",
      "\n",
      "wta_noise = nest.Create('poisson_generator', 10, {'rate': 3000.})\n",
      "nest.Connect(wta_noise, all_actions, 'all_to_all', {'weight': wta_noise_weights})\n",
      "nest.Connect(wta_noise, wta_inh_neurons, 'all_to_all', {'weight': wta_noise_weights * 0.9})\n",
      "\n",
      "\n",
      "# Create stimulus\n",
      "stimulus = nest.Create('poisson_generator', 1, {'rate': 5000.})\n",
      "nest.Connect(stimulus, all_states, 'all_to_all', {'weight': 0.})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gamma = 0.8\n",
      "def update_values(position, chosen_action, new_position, outcome):\n",
      "    # prediction error\n",
      "    current_value = np.mean(nest.GetStatus(nest.GetConnections(states[position['x']][position['y']], actions[chosen_action]), 'weight'))\n",
      "    new_value = np.max([np.mean(nest.GetStatus(nest.GetConnections(states[new_position['x']][new_position['y']], actions[a]), 'weight')) for a in range(len(actions))])\n",
      "    print current_value, new_value\n",
      "    prediction_error = outcome + gamma * new_value - current_value\n",
      "    \n",
      "    # update values\n",
      "    #values[position['x']][position['y']][chosen_action] += prediction_error * LEARNING_RATE \n",
      "    return prediction_error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Here, we are implementing the dopaminergic nueron pool, volume transmitter and dopamin-modulated synapse between states and actions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create DA pool\n",
      "DA_neurons = nest.Create('iaf_psc_alpha', 100)\n",
      "vol_trans = nest.Create('volume_transmitter', 1, {'deliver_interval': 10})\n",
      "nest.Connect(DA_neurons, vol_trans, 'all_to_all')\n",
      "\n",
      "# Create reward stimulus\n",
      "reward_stimulus = nest.Create('poisson_generator', 1, {'rate': 5000.})\n",
      "nest.Connect(reward_stimulus, DA_neurons, 'all_to_all', {'weight': 0.})\n",
      "\n",
      "tau_c = 500.0\n",
      "tau_n = 20.0\n",
      "\n",
      "# Connect states to actions\n",
      "nest.CopyModel('neuromod_dopa_synapse', 'dopa_synapse', {'vt': vol_trans[0], 'A_LTP': 400., 'A_LTD': 500.,\n",
      "                                                         'Wmin': -30., 'Wmax': 30., 'b': .095, 'tau_n': tau_n, 'tau_c': tau_c})\n",
      "        \n",
      "nest.Connect(all_states, all_actions, 'all_to_all', {'model': 'dopa_synapse', 'weight': 0.0})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create spike detector\n",
      "sd_wta = nest.Create('spike_detector')\n",
      "nest.Connect(all_actions, sd_wta)\n",
      "nest.Connect(wta_inh_neurons, sd_wta)\n",
      "sd_actions = nest.Create('spike_detector', num_actions)\n",
      "for i in range(len(actions)):\n",
      "    nest.Connect(actions[i], [sd_actions[i]])\n",
      "sd_states = nest.Create('spike_detector')\n",
      "nest.Connect(all_states, sd_states)\n",
      "sd_DA = nest.Create('spike_detector', 1)\n",
      "nest.Connect(DA_neurons, sd_DA, 'all_to_all')\n",
      "\n",
      "\n",
      "# Create noise\n",
      "noise = nest.Create('poisson_generator', 1, {'rate': 65000.})\n",
      "nest.Connect(noise, all_states, 'all_to_all', {'weight': 1.})\n",
      "nest.Connect(noise, DA_neurons, 'all_to_all', {'weight': 1.})\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_values(fig, ax, position):\n",
      "    plt.cla()\n",
      "    \n",
      "    values_plot = []      \n",
      "    \n",
      "    for i in range(world_dim['y']):\n",
      "        values_plot.append([])\n",
      "        for j in range(world_dim['x']):\n",
      "            values_plot[i].append(np.max([np.mean(nest.GetStatus(nest.GetConnections(states[j][i], actions[a]), 'weight')) for a in range(len(actions))]))\n",
      "            if len(actions) == 4:\n",
      "                q_north = np.mean(nest.GetStatus(nest.GetConnections(states[j][i], actions[0]), 'weight'))\n",
      "                q_east = np.mean(nest.GetStatus(nest.GetConnections(states[j][i], actions[1]), 'weight'))\n",
      "                q_south = np.mean(nest.GetStatus(nest.GetConnections(states[j][i], actions[2]), 'weight'))\n",
      "                q_west = np.mean(nest.GetStatus(nest.GetConnections(states[j][i], actions[3]), 'weight'))\n",
      "                ax.arrow(j, i, (q_east-q_west)/10., (q_south-q_north)/10., head_width=0.05, head_length=0.1, fc='k', ec='k')\n",
      "            else:\n",
      "                q_east = np.mean(nest.GetStatus(nest.GetConnections(states[j][i], actions[0]), 'weight'))\n",
      "                q_west = np.mean(nest.GetStatus(nest.GetConnections(states[j][i], actions[1]), 'weight'))\n",
      "                ax.arrow(j, i, (q_west-q_east)/10., 0., head_width=0.05, head_length=0.1, fc='k', ec='k')\n",
      "\n",
      "    \n",
      "    values_plot = np.array(values_plot)\n",
      "    print values_plot\n",
      "    \n",
      "    plt.imshow(values_plot, interpolation='none', vmax=1, vmin=-1)\n",
      "    \n",
      "    xlabels = np.arange(0, len(states))\n",
      "    ylabels = np.arange(0, len(states[0]))\n",
      "\n",
      "    # Set the major ticks at the centers and minor tick at the edges\n",
      "    xlocs = np.arange(len(xlabels))\n",
      "    ylocs = np.arange(len(ylabels))\n",
      "    ax.xaxis.set_ticks(xlocs + 0.5, minor=True)\n",
      "    ax.xaxis.set(ticks=xlocs, ticklabels=xlabels)\n",
      "    ax.yaxis.set_ticks(ylocs + 0.5, minor=True)\n",
      "    ax.yaxis.set(ticks=ylocs, ticklabels=ylabels)\n",
      "    \n",
      "    # Turn on the grid for the minor ticks\n",
      "    ax.grid(True, which='minor', linestyle='-', linewidth=2)   \n",
      "    \n",
      "    for txt in ax.texts:\n",
      "        txt.set_visible(False)\n",
      "        \n",
      "    ax.annotate(\".\", ((position['x'] + 0.5)/len(states), (1-(position['y'] + 0.5)/len(states[0]))), size=160, textcoords='axes fraction', color='white')\n",
      "    plt.draw()\n",
      "    \n",
      "    \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Main loop\n",
      "actions_executed = 0\n",
      "last_action_time = 0\n",
      "in_end_position = False\n",
      "\n",
      "# interactive plotting\n",
      "fig, ax = plt.subplots()\n",
      "plt.ion()\n",
      "    \n",
      "while actions_executed < NUM_ITERATIONS:\n",
      "    position = env.get_agent_pos().copy()\n",
      "\n",
      "    # plotting\n",
      "    plot_values(fig, ax, position)\n",
      "    \n",
      "    if not in_end_position:\n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[position['x']][position['y']]), {'weight': 1.})\n",
      "        \n",
      "        nest.SetStatus(wta_noise, {'rate': 3000.})\n",
      "        nest.Simulate(400)\n",
      "        max_rate = -1\n",
      "        chosen_action = -1\n",
      "        for i in range(len(sd_actions)):\n",
      "            rate = len([e for e in nest.GetStatus([sd_actions[i]], keys='events')[0]['times'] if e > last_action_time]) # calc the \"firerate\" of each actor population\n",
      "            if rate > max_rate:\n",
      "                max_rate = rate # the population with the hightes rate wins\n",
      "                chosen_action = i\n",
      "        nest.SetStatus(stimulus, {'rate': 5000.})\n",
      "\n",
      "        possible_actions = env.get_possible_actions() \n",
      "\n",
      "        new_position, outcome, in_end_position = env.move(possible_actions[chosen_action])\n",
      "\n",
      "        prediction_error = update_values(position, chosen_action, new_position, outcome)\n",
      "\n",
      "        print \"iteration:\", actions_executed, \"action:\", chosen_action \n",
      "        print \"new pos:\", new_position, \"reward:\", outcome, \"prediction error:\", prediction_error\n",
      "\n",
      "        policy = []\n",
      "        policy.append(np.mean(nest.GetStatus(nest.GetConnections(states[1][0], actions[0]), 'weight')))\n",
      "        policy.append(np.mean(nest.GetStatus(nest.GetConnections(states[1][0], actions[1]), 'weight')))\n",
      "        \n",
      "        print \"policy:\", policy#, \"values:\", values[1][0]\n",
      "        \n",
      "        # stimulate new state\n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[position['x']][position['y']]), {'weight': 0.})\n",
      "\n",
      "         \n",
      "        # apply reward\n",
      "        nest.SetStatus(nest.GetConnections(reward_stimulus, DA_neurons), {'weight': float(prediction_error)})\n",
      "        nest.SetStatus(wta_noise, {'rate': 0.})\n",
      "        \n",
      "        # refactory time\n",
      "        nest.Simulate(100.)\n",
      "        \n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[new_position['x']][new_position['y']]), {'weight': 1.})\n",
      "        nest.SetStatus(nest.GetConnections(reward_stimulus, DA_neurons), {'weight': 0.0})\n",
      "              \n",
      "        last_action_time += 500\n",
      "        actions_executed += 1\n",
      "    else:      \n",
      "        _, in_end_position = env.init_new_trial()\n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[position['x']][position['y']]), {'weight': 0.})\n",
      "\n",
      "\n",
      "rplt.from_device(sd_wta, title=\"WTA circuit\")\n",
      "rplt.from_device(sd_states, title=\"States\")\n",
      "rplt.from_device(sd_DA, title=\"DA pool\")\n",
      "rplt.show()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/usr/lib/pymodules/python2.7/matplotlib/patches.py:1054: RuntimeWarning: invalid value encountered in double_scalars\n",
        "/usr/lib/pymodules/python2.7/matplotlib/patches.py:1055: RuntimeWarning: invalid value encountered in double_scalars\n",
        "[[ 0.  0.  0.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-0.005918502179"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -1.45566115647e-06\n",
        "iteration: 0 action: 1\n",
        "new pos: {'y': 0, 'x': 2} reward: -1.0 prediction error: -0.99408266235\n",
        "policy: [2.9737694862424242e-05, -0.0059185021790038317]\n",
        "[[  2.50619517e-03   1.51861279e-05  -1.03532623e-05]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[  2.50619517e-03   1.51861279e-05  -1.03532623e-05]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.155579048063"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0116102152134\n",
        "iteration: 1 action: 0\n",
        "new pos: {'y': 0, 'x': 0} reward: 1.0 prediction error: 0.853709124108\n",
        "policy: [0.1555790480629558, -0.007087594081181015]\n",
        "[[ 0.02134121  0.34850308  0.01904451]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 0.02134121  0.34850308  0.01904451]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0340430226"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0191971185588\n",
        "iteration: 2 action: 1\n",
        "new pos: {'y': 0, 'x': 2} reward: -1.0 prediction error: -1.01868532775\n",
        "policy: [0.34894649111473347, 0.03404302259999302]\n",
        "[[ 0.02131326  0.34892571  0.01919492]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 0.02131326  0.34892571  0.01919492]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0281172689254"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0193403861197\n",
        "iteration: 3 action: 1\n",
        "new pos: {'y': 0, 'x': 2} reward: -1.0 prediction error: -1.01264496003\n",
        "policy: [0.35040615095677019, 0.028117268925361694]\n",
        "[[ 0.02145837  0.35040614  0.01934038]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 0.02145837  0.35040614  0.01934038]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.026439731666"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0193967301661\n",
        "iteration: 4 action: 1\n",
        "new pos: {'y': 0, 'x': 2} reward: -1.0 prediction error: -1.01092234753\n",
        "policy: [0.35016063817207105, 0.026439731665970672]\n",
        "[[ 0.02143867  0.3501594   0.01939658]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 0.02143867  0.3501594   0.01939658]]"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}