{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Artificial Predicion Error"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "In the exercises before, we implemented a WTA circuit which was randomly choosing actions in a simple environment. Now, we want to learn which choises lead to reward and which to punishment. Finally we want to change the behavior of the system according to the learnt poicy."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1.) 1 State - 2 Actions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import nest\n",
      "import nest.raster_plot as rplt\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import environment as env"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "As in the exercise before, we set up a simple environment and create a WTA circuit to choose actions within this environment."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "env.set_environment(0)\n",
      "\n",
      "\n",
      "NUM_ITERATIONS = 50\n",
      "LEARNING_RATE = 0.05\n",
      "NUM_STATE_NEURONS = 20\n",
      "NUM_WTA_NEURONS = 50\n",
      "WEIGHT_SCALING = 100 / NUM_STATE_NEURONS\n",
      "\n",
      "nest.ResetKernel()\n",
      "nest.set_verbosity(\"M_DEBUG\")\n",
      "\n",
      "rank = nest.Rank()\n",
      "size = nest.NumProcesses() \n",
      "seed = np.random.randint(0, 1000000)\n",
      "num_threads = 4\n",
      "nest.SetKernelStatus({\"local_num_threads\": num_threads})\n",
      "nest.SetKernelStatus({\"rng_seeds\": range(seed+num_threads * size + 1, seed + 2 * (num_threads * size) + 1),\n",
      "        \t\t      \"grng_seed\": seed+size+num_threads,\n",
      "                      \"resolution\": 0.1})\n",
      "\n",
      "# Create states\n",
      "world_dim = env.get_world_dimensions()\n",
      "states = []\n",
      "for i in range(world_dim['x']):\n",
      "    states.append(nest.Create('iaf_psc_alpha', NUM_STATE_NEURONS))\n",
      "all_states = np.ravel(states).tolist()\n",
      "\n",
      "# Create actions\n",
      "num_actions = env.get_num_possible_actions()[0][1]\n",
      "actions = []\n",
      "for i in range(num_actions):\n",
      "    actions.append(nest.Create('iaf_psc_alpha', NUM_WTA_NEURONS))\n",
      "all_actions = np.ravel(actions).tolist()\n",
      "\n",
      "# Create WTA circuit\n",
      "wta_ex_weights = 10.5\n",
      "wta_inh_weights = -2.6\n",
      "wta_ex_inh_weights = 2.8\n",
      "wta_noise_weights = 2.1\n",
      "\n",
      "wta_inh_neurons = nest.Create('iaf_psc_alpha', NUM_WTA_NEURONS)\n",
      "\n",
      "for i in range(len(actions)):\n",
      "    nest.Connect(actions[i], actions[i], 'all_to_all', {'weight': wta_ex_weights})\n",
      "    nest.Connect(actions[i], wta_inh_neurons, 'all_to_all', {'weight': wta_ex_inh_weights}) \n",
      "\n",
      "nest.Connect(wta_inh_neurons, all_actions, 'all_to_all', {'weight': wta_inh_weights})\n",
      "\n",
      "wta_noise = nest.Create('poisson_generator', 10, {'rate': 3000.})\n",
      "nest.Connect(wta_noise, all_actions, 'all_to_all', {'weight': wta_noise_weights})\n",
      "nest.Connect(wta_noise, wta_inh_neurons, 'all_to_all', {'weight': wta_noise_weights * 0.9})\n",
      "\n",
      "# Create noise\n",
      "noise = nest.Create('poisson_generator', 1, {'rate': 65000.})\n",
      "nest.Connect(noise, all_states, 'all_to_all', {'weight': 1.})\n",
      "\n",
      "# Create stimulus\n",
      "stimulus = nest.Create('poisson_generator', 1, {'rate': 5000.})\n",
      "position = env.get_agent_pos()['x']\n",
      "nest.Connect(stimulus, states[position], 'all_to_all', {'weight': 1.})\n",
      "\n",
      "# Create spike detector\n",
      "sd_wta = nest.Create('spike_detector')\n",
      "nest.Connect(all_actions, sd_wta)\n",
      "sd_actions = nest.Create('spike_detector', num_actions)\n",
      "for i in range(len(actions)):\n",
      "    nest.Connect(actions[i], [sd_actions[i]])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "This time we estimate the valence of each action in 'values' and connect the state population to the action populations accordingly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Value expectations for Q(s,a)\n",
      "values = np.zeros(num_actions)\n",
      "    \n",
      "# Connect states to actions\n",
      "nest.Connect(states[1], actions[0], 'all_to_all', {'weight': values[0]})\n",
      "nest.Connect(states[1], actions[1], 'all_to_all', {'weight': values[1]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "After each selected action, this function is called which will update the valence of the state."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def update_values(chosen_action, outcome):\n",
      "    # prediction error\n",
      "    prediction_error = outcome - values[chosen_action]\n",
      "\n",
      "    # update values\n",
      "    values[chosen_action] += prediction_error * LEARNING_RATE  \n",
      "\n",
      "    # save values for plotting\n",
      "    values_hist.append(values.copy())\n",
      "    return prediction_error\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "And finally we run the simulation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Main loop\n",
      "values_hist = [values.copy()]\n",
      "actions_executed = 0\n",
      "last_action_time = 0\n",
      "in_end_position = False\n",
      "\n",
      "while actions_executed < NUM_ITERATIONS:\n",
      "    if not in_end_position:\n",
      "        nest.SetStatus(wta_noise, {'rate': 3000.})\n",
      "        nest.Simulate(200)\n",
      "        max_rate = -1\n",
      "        chosen_action = -1\n",
      "        for i in range(len(sd_actions)):\n",
      "            rate = len([e for e in nest.GetStatus([sd_actions[i]], keys='events')[0]['times'] if e > last_action_time]) # calc the \"firerate\" of each actor population\n",
      "            if rate > max_rate:\n",
      "                max_rate = rate # the population with the hightes rate wins\n",
      "                chosen_action = i\n",
      "        nest.SetStatus(stimulus, {'rate': 5000.})\n",
      "\n",
      "        possible_actions = env.get_possible_actions() \n",
      "\n",
      "        _, outcome, in_end_position = env.move(possible_actions[chosen_action])\n",
      "\n",
      "        prediction_error = update_values(chosen_action, outcome)\n",
      "        print \"iteration:\", actions_executed, \"action:\", chosen_action, \"reward:\", outcome, \"updated values\", values, \"predicion error:\", prediction_error\n",
      "\n",
      "\n",
      "        for i in range(num_actions):\n",
      "            nest.SetStatus(nest.GetConnections(states[1], actions[i]), {'weight': values[i] * WEIGHT_SCALING})\n",
      "\n",
      "        nest.SetStatus(wta_noise, {'rate': 0.})\n",
      "        nest.Simulate(50.)\n",
      "\n",
      "        last_action_time += 1000\n",
      "        actions_executed += 1\n",
      "    else:\n",
      "        _, in_end_position = env.init_new_trial()\n",
      "\n",
      "       \n",
      "plt.xlabel(\"# action\")\n",
      "plt.ylabel(\"valence\")\n",
      "plt.title(\"valence of each action\")\n",
      "plt.plot(values_hist)\n",
      "rplt.from_device(sd_wta, title=\"WTA circuit\")\n",
      "rplt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Exercises:\n",
      "Change the iterations and learning rate. What is the pro and contra of high learning rates?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.) Multi State - 2 Actions"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "!!! PLEASE RESTART KERNEL HERE !!!\n",
      "\n",
      "In this example show how to handle multiple states."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nest\n",
      "import nest.raster_plot as rplt\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "import environment as env\n",
      "from mpl_toolkits.mplot3d import Axes3D"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "env.set_environment(1)\n",
      "\n",
      "\n",
      "NUM_ITERATIONS = 30\n",
      "LEARNING_RATE = 0.5\n",
      "NUM_STATE_NEURONS = 20\n",
      "NUM_WTA_NEURONS = 50\n",
      "WEIGHT_SCALING = 100 / NUM_STATE_NEURONS\n",
      "\n",
      "nest.ResetKernel()\n",
      "nest.set_verbosity(\"M_DEBUG\")\n",
      "\n",
      "rank = nest.Rank()\n",
      "size = nest.NumProcesses() \n",
      "seed = np.random.randint(0, 1000000)\n",
      "num_threads = 4\n",
      "nest.SetKernelStatus({\"local_num_threads\": num_threads})\n",
      "nest.SetKernelStatus({\"rng_seeds\": range(seed+num_threads * size + 1, seed + 2 * (num_threads * size) + 1),\n",
      "        \t\t      \"grng_seed\": seed+size+num_threads,\n",
      "                      \"resolution\": 0.1})\n",
      "\n",
      "\n",
      "# Create states\n",
      "world_dim = env.get_world_dimensions()\n",
      "states = []\n",
      "for i in range(world_dim['x']):\n",
      "    states.append(nest.Create('iaf_psc_alpha', NUM_STATE_NEURONS))\n",
      "all_states = np.ravel(states).tolist()\n",
      "\n",
      "# Create actions\n",
      "num_actions = env.get_num_possible_actions()[0][1]\n",
      "actions = []\n",
      "for i in range(num_actions):\n",
      "    actions.append(nest.Create('iaf_psc_alpha', NUM_WTA_NEURONS))\n",
      "all_actions = np.ravel(actions).tolist()\n",
      "\n",
      "# Create WTA circuit\n",
      "wta_ex_weights = 10.5\n",
      "wta_inh_weights = -2.6\n",
      "wta_ex_inh_weights = 2.8\n",
      "wta_noise_weights = 2.1\n",
      "\n",
      "wta_inh_neurons = nest.Create('iaf_psc_alpha', NUM_WTA_NEURONS)\n",
      "\n",
      "for i in range(len(actions)):\n",
      "    nest.Connect(actions[i], actions[i], 'all_to_all', {'weight': wta_ex_weights})\n",
      "    nest.Connect(actions[i], wta_inh_neurons, 'all_to_all', {'weight': wta_ex_inh_weights}) \n",
      "\n",
      "nest.Connect(wta_inh_neurons, all_actions, 'all_to_all', {'weight': wta_inh_weights})\n",
      "\n",
      "wta_noise = nest.Create('poisson_generator', 10, {'rate': 3000.})\n",
      "nest.Connect(wta_noise, all_actions, 'all_to_all', {'weight': wta_noise_weights})\n",
      "nest.Connect(wta_noise, wta_inh_neurons, 'all_to_all', {'weight': wta_noise_weights * 0.9})\n",
      "\n",
      "# Create noise\n",
      "noise = nest.Create('poisson_generator', 1, {'rate': 65000.})\n",
      "nest.Connect(noise, all_states, 'all_to_all', {'weight': 1.})\n",
      "\n",
      "# Create stimulus\n",
      "stimulus = nest.Create('poisson_generator', 1, {'rate': 5000.})\n",
      "nest.Connect(stimulus, all_states, 'all_to_all', {'weight': 0.})\n",
      "\n",
      "# Create spike detector\n",
      "sd_wta = nest.Create('spike_detector')\n",
      "nest.Connect(all_actions, sd_wta)\n",
      "sd_actions = nest.Create('spike_detector', num_actions)\n",
      "for i in range(len(actions)):\n",
      "    nest.Connect(actions[i], [sd_actions[i]])\n",
      "sd_states = nest.Create('spike_detector')\n",
      "nest.Connect(all_states, sd_states)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Create values for each action in each state of the environment."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Value expectations for Q(s,a)\n",
      "values = np.array([np.zeros(num_actions) for i in range(world_dim['x'])])\n",
      "        \n",
      "# Connect states to actions with initial weight 0.0\n",
      "nest.Connect(all_states, all_actions, 'all_to_all', {'weight': 0.0})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gamma = 0.8\n",
      "\n",
      "def update_values(position, chosen_action, new_position, outcome):\n",
      "    # prediction error\n",
      "    best_new_action = values[new_position].argmax()\n",
      "    prediction_error = outcome + gamma * values[new_position][best_new_action] - values[position][chosen_action]\n",
      "\n",
      "    # update values\n",
      "    values[position][chosen_action] += prediction_error * LEARNING_RATE \n",
      "\n",
      "    # save values for plotting\n",
      "    values_hist.append(np.ravel(values.copy()))\n",
      "    \n",
      "    return prediction_error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_values(fig, ax, position):\n",
      "    plt.cla()\n",
      "    \n",
      "    values_plot = [[]]\n",
      "\n",
      "    \n",
      "    for i in range(len(states)):\n",
      "        values_plot[0].append(max(values[i]))\n",
      "    \n",
      "    xlabels = np.arange(0, len(states))\n",
      "    ylabels = np.arange(0, len(states[0]))\n",
      "\n",
      "    # Set the major ticks at the centers and minor tick at the edges\n",
      "    xlocs = np.arange(len(xlabels))\n",
      "    ylocs = np.arange(len(ylabels))\n",
      "    ax.xaxis.set_ticks(xlocs + 0.5, minor=True)\n",
      "    ax.xaxis.set(ticks=xlocs, ticklabels=xlabels)\n",
      "    ax.yaxis.set_ticks(ylocs + 0.5, minor=True)\n",
      "    ax.yaxis.set(ticks=ylocs, ticklabels=ylabels)\n",
      "    \n",
      "    # Turn on the grid for the minor ticks\n",
      "    ax.grid(True, which='minor', linestyle='-', linewidth=2)   \n",
      "    plt.imshow(values_plot, interpolation='None', vmin=0, vmax=1)\n",
      "    \n",
      "    for txt in ax.texts:\n",
      "        txt.set_visible(False)\n",
      "        \n",
      "    ax.annotate(\".\", ((position['x'] + 0.5)/len(states), 0.5), size=160, textcoords='axes fraction')\n",
      "    plt.draw()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Main loop\n",
      "values_hist = [np.ravel(values.copy())]\n",
      "actions_executed = 0\n",
      "last_action_time = 0\n",
      "in_end_position = False\n",
      "\n",
      "# interactive plotting\n",
      "fig, ax = plt.subplots()\n",
      "plt.ion()\n",
      "\n",
      "\n",
      "\n",
      "while actions_executed < NUM_ITERATIONS:\n",
      "    position = env.get_agent_pos().copy()    \n",
      "    \n",
      "    # plotting\n",
      "    plot_values(fig, ax, position)\n",
      "    \n",
      "    if not in_end_position:        \n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[position['x']]), {'weight': 1.})\n",
      "        \n",
      "        nest.SetStatus(wta_noise, {'rate': 3000.})\n",
      "        nest.Simulate(200)\n",
      "        max_rate = -1\n",
      "        chosen_action = -1\n",
      "        for i in range(len(sd_actions)):\n",
      "            rate = len([e for e in nest.GetStatus([sd_actions[i]], keys='events')[0]['times'] if e > last_action_time]) # calc the \"firerate\" of each actor population\n",
      "            if rate > max_rate:\n",
      "                max_rate = rate # the population with the hightes rate wins\n",
      "                chosen_action = i\n",
      "        nest.SetStatus(stimulus, {'rate': 5000.})\n",
      "\n",
      "        possible_actions = env.get_possible_actions() \n",
      "\n",
      "        new_position, outcome, in_end_position = env.move(possible_actions[chosen_action])\n",
      "\n",
      "        prediction_error = update_values(position['x'], chosen_action, new_position['x'], outcome)\n",
      "        \n",
      "        print \"iteration:\", actions_executed, \"action:\", chosen_action\n",
      "        print \"new position:\", new_position['x'], \"reward:\", outcome, \"updated_values:\", values[position['x']], \"prediction error:\", prediction_error\n",
      "\n",
      "        for i in range(num_actions):\n",
      "            nest.SetStatus(nest.GetConnections(states[position['x']], actions[i]), {'weight': values[position['x']][i] * WEIGHT_SCALING})\n",
      "            \n",
      "        # stimulate new state\n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[position['x']]), {'weight': 0.})\n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[new_position['x']]), {'weight': 1.})\n",
      "\n",
      "        nest.SetStatus(wta_noise, {'rate': 0.})\n",
      "        nest.Simulate(50.)\n",
      "\n",
      "        last_action_time += 250\n",
      "        actions_executed += 1\n",
      "    else:\n",
      "        _, in_end_position = env.init_new_trial()\n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[position['x']]), {'weight': 0.})\n",
      "        \n",
      "\n",
      "    \n",
      "   \n",
      "#rplt.from_device(sd_wta, title=\"WTA circuit\")\n",
      "#rplt.from_device(sd_states, title=\"states\")\n",
      "#rplt.show()\n",
      "\n",
      "#fig = plt.figure()\n",
      "\n",
      "#plt.xlabel(\"# action\")\n",
      "#plt.ylabel(\"valence\")\n",
      "#plt.title(\"valence of each action\")\n",
      "#ax = fig.add_subplot(111, projection='3d')\n",
      "\n",
      "#x, y = np.meshgrid(range(world_dim['x'] * num_actions), range(NUM_ITERATIONS))\n",
      "#x = x.flatten()\n",
      "#y = y.flatten()\n",
      "\n",
      "#ax.bar3d(x, y, np.zeros(len(x)), np.ones(len(x)) * 0.5, np.ones(len(x)) * 0.5, np.ravel(values_hist))\n",
      "\n",
      "#plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.) Grid World --- Multiple States - 4 Actions"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "!!! PLEASE RESTART KERNEL HERE !!!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nest\n",
      "import nest.raster_plot as rplt\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import environment as env\n",
      "from mpl_toolkits.mplot3d import Axes3D"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "env.set_environment(7)\n",
      "\n",
      "NUM_ITERATIONS = 2000\n",
      "LEARNING_RATE = 0.5\n",
      "NUM_STATE_NEURONS = 20\n",
      "NUM_WTA_NEURONS = 50\n",
      "WEIGHT_SCALING = 100 / NUM_STATE_NEURONS\n",
      "\n",
      "nest.ResetKernel()\n",
      "nest.set_verbosity(\"M_DEBUG\")\n",
      "\n",
      "rank = nest.Rank()\n",
      "size = nest.NumProcesses() \n",
      "seed = np.random.randint(0, 1000000)\n",
      "num_threads = 4\n",
      "nest.SetKernelStatus({\"local_num_threads\": num_threads})\n",
      "nest.SetKernelStatus({\"rng_seeds\": range(seed+num_threads * size + 1, seed + 2 * (num_threads * size) + 1),\n",
      "        \t\t      \"grng_seed\": seed+size+num_threads,\n",
      "                      \"resolution\": 0.1})\n",
      "\n",
      "# Create states\n",
      "world_dim = env.get_world_dimensions()\n",
      "states = []\n",
      "for i in range(world_dim['x']):\n",
      "    states.append([])\n",
      "    for j in range(world_dim['y']):\n",
      "        states[i].append(nest.Create('iaf_psc_alpha', NUM_STATE_NEURONS))\n",
      "all_states = np.ravel(states).tolist()\n",
      "\n",
      "# Create actions\n",
      "num_actions = env.get_num_possible_actions()[0][1]\n",
      "actions = []\n",
      "for i in range(num_actions):\n",
      "    actions.append(nest.Create('iaf_psc_alpha', NUM_WTA_NEURONS))\n",
      "all_actions = np.ravel(actions).tolist()\n",
      "\n",
      "# Create WTA circuit\n",
      "wta_ex_weights = 10.5\n",
      "wta_inh_weights = -2.6\n",
      "wta_ex_inh_weights = 2.8\n",
      "wta_noise_weights = 2.1\n",
      "\n",
      "wta_inh_neurons = nest.Create('iaf_psc_alpha', NUM_WTA_NEURONS)\n",
      "\n",
      "for i in range(len(actions)):\n",
      "    nest.Connect(actions[i], actions[i], 'all_to_all', {'weight': wta_ex_weights})\n",
      "    nest.Connect(actions[i], wta_inh_neurons, 'all_to_all', {'weight': wta_ex_inh_weights}) \n",
      "\n",
      "nest.Connect(wta_inh_neurons, all_actions, 'all_to_all', {'weight': wta_inh_weights})\n",
      "\n",
      "wta_noise = nest.Create('poisson_generator', 10, {'rate': 3000.})\n",
      "nest.Connect(wta_noise, all_actions, 'all_to_all', {'weight': wta_noise_weights})\n",
      "nest.Connect(wta_noise, wta_inh_neurons, 'all_to_all', {'weight': wta_noise_weights * 0.9})\n",
      "\n",
      "# Create noise\n",
      "noise = nest.Create('poisson_generator', 1, {'rate': 65000.})\n",
      "nest.Connect(noise, all_states, 'all_to_all', {'weight': 1.})\n",
      "\n",
      "# Create stimulus\n",
      "stimulus = nest.Create('poisson_generator', 1, {'rate': 5000.})\n",
      "nest.Connect(stimulus, all_states, 'all_to_all', {'weight': 0.})\n",
      "\n",
      "# Create spike detector\n",
      "sd_wta = nest.Create('spike_detector')\n",
      "nest.Connect(all_actions, sd_wta)\n",
      "nest.Connect(wta_inh_neurons, sd_wta)\n",
      "sd_actions = nest.Create('spike_detector', num_actions)\n",
      "for i in range(len(actions)):\n",
      "    nest.Connect(actions[i], [sd_actions[i]])\n",
      "sd_states = nest.Create('spike_detector')\n",
      "nest.Connect(all_states, sd_states)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "values = []\n",
      "# Value expectations for Q(s,a)\n",
      "for i in range(world_dim['x']):\n",
      "    values.append([])\n",
      "    for j in range(world_dim['y']):\n",
      "        values[i].append(np.zeros(num_actions))\n",
      "        \n",
      "# Connect states to actions with initial weight 0.0\n",
      "nest.Connect(all_states, all_actions, 'all_to_all', {'weight': 0.0})\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gamma = 0.8\n",
      "\n",
      "def update_values(position, chosen_action, new_position, outcome):\n",
      "    # prediction error\n",
      "    best_new_action = values[new_position['x']][new_position['y']].argmax()\n",
      "    prediction_error = outcome + gamma * values[new_position['x']][new_position['y']][best_new_action] - values[position['x']][position['y']][chosen_action]\n",
      "    \n",
      "    # update values\n",
      "    values[position['x']][position['y']][chosen_action] += prediction_error * LEARNING_RATE \n",
      "    return prediction_error\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_values(fig, ax, position):\n",
      "    plt.cla()\n",
      "    \n",
      "    values_plot = []      \n",
      "    \n",
      "    for i in range(world_dim['y']):\n",
      "        values_plot.append([])\n",
      "        for j in range(world_dim['x']):\n",
      "            values_plot[i].append(np.max(values[j][i]))\n",
      "    \n",
      "    values_plot = np.array(values_plot)\n",
      "    \n",
      "    plt.imshow(values_plot, interpolation='none', vmax= 1, vmin = 0)\n",
      "    \n",
      "    xlabels = np.arange(0, len(states))\n",
      "    ylabels = np.arange(0, len(states[0]))\n",
      "\n",
      "    # Set the major ticks at the centers and minor tick at the edges\n",
      "    xlocs = np.arange(len(xlabels))\n",
      "    ylocs = np.arange(len(ylabels))\n",
      "    ax.xaxis.set_ticks(xlocs + 0.5, minor=True)\n",
      "    ax.xaxis.set(ticks=xlocs, ticklabels=xlabels)\n",
      "    ax.yaxis.set_ticks(ylocs + 0.5, minor=True)\n",
      "    ax.yaxis.set(ticks=ylocs, ticklabels=ylabels)\n",
      "    \n",
      "    # Turn on the grid for the minor ticks\n",
      "    ax.grid(True, which='minor', linestyle='-', linewidth=2)   \n",
      "    \n",
      "    for txt in ax.texts:\n",
      "        txt.set_visible(False)\n",
      "        \n",
      "    ax.annotate(\".\", ((position['x'] + 0.5)/len(states), (1-(position['y'] + 0.5)/len(states[0]))), size=160, textcoords='axes fraction', color='white')\n",
      "    plt.draw()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Main loop\n",
      "actions_executed = 0\n",
      "last_action_time = 0\n",
      "in_end_position = False\n",
      "\n",
      "# interactive plotting\n",
      "fig, ax = plt.subplots()\n",
      "plt.ion()\n",
      "    \n",
      "while actions_executed < NUM_ITERATIONS:\n",
      "    position = env.get_agent_pos().copy()\n",
      "    # plotting\n",
      "    plot_values(fig, ax, position)\n",
      "    \n",
      "    if not in_end_position:        \n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[position['x']][position['y']]), {'weight': 1.})\n",
      "        \n",
      "        nest.SetStatus(wta_noise, {'rate': 3000.})\n",
      "        nest.Simulate(200)\n",
      "        max_rate = -1\n",
      "        chosen_action = -1\n",
      "        for i in range(len(sd_actions)):\n",
      "            rate = len([e for e in nest.GetStatus([sd_actions[i]], keys='events')[0]['times'] if e > last_action_time]) # calc the \"firerate\" of each actor population\n",
      "            if rate > max_rate:\n",
      "                max_rate = rate # the population with the hightes rate wins\n",
      "                chosen_action = i\n",
      "        nest.SetStatus(stimulus, {'rate': 5000.})\n",
      "\n",
      "        possible_actions = env.get_possible_actions() \n",
      "\n",
      "        new_position, outcome, in_end_position = env.move(possible_actions[chosen_action])\n",
      "\n",
      "        prediction_error = update_values(position, chosen_action, new_position, outcome)\n",
      "        print \"iteration:\", actions_executed, \"action:\", chosen_action \n",
      "        print \"new pos:\", new_position, \"reward:\", outcome, \"updated values:\", values[position['x']][position['y']], \"prediction error:\", prediction_error\n",
      "\n",
      "        for i in range(num_actions):\n",
      "            nest.SetStatus(nest.GetConnections(states[position['x']][position['y']], actions[i]), {'weight': values[position['x']][position['y']][i] * WEIGHT_SCALING})\n",
      "            \n",
      "        # stimulate new state\n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[position['x']][position['y']]), {'weight': 0.})\n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[new_position['x']][new_position['y']]), {'weight': 1.})\n",
      "\n",
      "        nest.SetStatus(wta_noise, {'rate': 0.})\n",
      "        nest.Simulate(50.)\n",
      "              \n",
      "        last_action_time += 250\n",
      "        actions_executed += 1\n",
      "    else:      \n",
      "        _, in_end_position = env.init_new_trial()\n",
      "        nest.SetStatus(nest.GetConnections(stimulus, states[position['x']][position['y']]), {'weight': 0.})\n",
      "\n",
      "\n",
      "rplt.from_device(sd_wta, title=\"WTA circuit\")\n",
      "rplt.from_device(sd_states, title=\"states\")\n",
      "rplt.show()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "iteration: 0 action: 2\n",
        "new pos: {'y': 1, 'x': 0} reward: 0 updated values: [ 0.  0.  0.  0.] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 action: 0\n",
        "new pos: {'y': 0, 'x': 0} reward: 0 updated values: [ 0.  0.  0.  0.] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2 action: 2\n",
        "new pos: {'y': 1, 'x': 0} reward: 0 updated values: [ 0.  0.  0.  0.] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3 action: 3\n",
        "new pos: {'y': 1, 'x': 0} reward: -1 updated values: [ 0.   0.   0.  -0.5] prediction error: -1.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4 action: 0\n",
        "new pos: {'y': 0, 'x': 0} reward: 0 updated values: [ 0.   0.   0.  -0.5] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5 action: 2\n",
        "new pos: {'y': 1, 'x': 0} reward: 0 updated values: [ 0.  0.  0.  0.] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6 action: 2\n",
        "new pos: {'y': 2, 'x': 0} reward: 0 updated values: [ 0.   0.   0.  -0.5] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7 action: 0\n",
        "new pos: {'y': 1, 'x': 0} reward: 0 updated values: [ 0.  0.  0.  0.] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8 action: 2\n",
        "new pos: {'y': 2, 'x': 0} reward: 0 updated values: [ 0.   0.   0.  -0.5] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9 action: 3\n",
        "new pos: {'y': 2, 'x': 0} reward: -1 updated values: [ 0.   0.   0.  -0.5] prediction error: -1.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 action: 1\n",
        "new pos: {'y': 2, 'x': 1} reward: 0 updated values: [ 0.   0.   0.  -0.5] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11 action: 1\n",
        "new pos: {'y': 2, 'x': 2} reward: 1.0 updated values: [ 0.   0.5  0.   0. ] prediction error: 1.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12 action: 3\n",
        "new pos: {'y': 0, 'x': 0} reward: -1 updated values: [ 0.   0.   0.  -0.5] prediction error: -1.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13 action: 1\n",
        "new pos: {'y': 0, 'x': 1} reward: 0 updated values: [ 0.   0.   0.  -0.5] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14 action: 3\n",
        "new pos: {'y': 0, 'x': 0} reward: 0 updated values: [ 0.  0.  0.  0.] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15 action: 1\n",
        "new pos: {'y': 0, 'x': 1} reward: 0 updated values: [ 0.   0.   0.  -0.5] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16 action: 1\n",
        "new pos: {'y': 0, 'x': 2} reward: 0 updated values: [ 0.  0.  0.  0.] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17 action: 1\n",
        "new pos: {'y': 0, 'x': 2} reward: -1 updated values: [ 0.  -0.5  0.   0. ] prediction error: -1.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18 action: 2\n",
        "new pos: {'y': 1, 'x': 2} reward: 0 updated values: [ 0.  -0.5  0.   0. ] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19 action: 1\n",
        "new pos: {'y': 1, 'x': 2} reward: -1 updated values: [ 0.  -0.5  0.   0. ] prediction error: -1.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20 action: 0\n",
        "new pos: {'y': 0, 'x': 2} reward: 0 updated values: [ 0.  -0.5  0.   0. ] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21 action: 0\n",
        "new pos: {'y': 0, 'x': 2} reward: -1 updated values: [-0.5 -0.5  0.   0. ] prediction error: -1.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22 action: 2\n",
        "new pos: {'y': 1, 'x': 2} reward: 0 updated values: [-0.5 -0.5  0.   0. ] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23 action: 0\n",
        "new pos: {'y': 0, 'x': 2} reward: 0 updated values: [ 0.  -0.5  0.   0. ] prediction error: 0.0\n",
        "iteration:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24 action: 2\n",
        "new pos: {'y': 1, 'x': 2} reward: 0 updated values: [-0.5 -0.5  0.   0. ] prediction error: 0.0\n",
        "iteration:"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}